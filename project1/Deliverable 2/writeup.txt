# Deliverable 2: Detailed Technique Report

## Introduction
-The credibility of online information has become a critical concern as individuals are increasingly overwhelmed by the volume and variability of available sources.
Traditional approaches to credibility assessment—whether human fact-checking or automated classifiers—either struggle with scalability or suffer from limited interpretability. 
To address this, our project proposes and implements a hybrid system for credibility scoring that balances efficiency, explainability, and adaptability.  

-The system begins with a rules-based foundation that evaluates URLs and metadata through transparent heuristics such as HTTPS usage, domain trustworthiness, and structural features. 
On top of this foundation, we integrate a lightweight natural language processing (NLP) layer to identify linguistic markers of low or high reliability, such as sensational or weasel words, excessive punctuation, or the presence of a DOI. 
Finally, a machine learning (ML) adjustment is layered in to capture more subtle tonal cues—such as emotional loading or bias—via sentiment analysis models.  

-This combination allows the prototype to demonstrate both immediate feasibility and future extensibility: 
The rules-based elements guarantee interpretability and reproducibility, the NLP layer ties the analysis to established linguistic research, and the ML adjustment provides a flexible entry point for integrating more advanced models
as they become available. In this way, the project demonstrates not only a proof of a possible, larger concept but also a practical roadmap that will be more realized in Deliverable 3.


## Algorithmic Foundation

### Rules-Based URL and Metadata Analysis
The core of the prototype relies on rules-based heuristics that examine structural and lexical properties of URLs:
- **Transport protocol:** HTTPS earns a positive increment, while HTTP is penalized.
- **Top-level domains (TLDs):** High-trust domains (.gov, .edu, .int) boost scores; low-trust TLDs (.xyz, .click) reduce them.
- **Reputable domain lists:** Domains such as pubmed.ncbi.nlm.nih.gov or nejm.org carry strong positive weights.
- **URL length and query parameters:** Overly long URLs or excessive tracking parameters reduce credibility.
- **Path hints:** Directories such as `/research` or `/doi/` suggest scholarly intent, while `/opinion` or `/promo` suggest subjectivity or marketing.

The algorithm begins with a neutral baseline score of 50, then adds or subtracts increments based on these features. Scores are clamped between 0 and 100 to ensure consistency. 
Complexity is constant time per URL, making this layer trivially scalable.

### NLP-Based Text Analysis
If article text is available, a secondary layer of analysis can be enabled. This module uses a lexicon- and regex-based approach to detect linguistic patterns associated with low or high credibility:
- Sensational terms: Words such as “miracle” or “shocking” decrease credibility.
- Weasel words: Phrases such as “some say” or “allegedly” are penalized for lack of attribution.
- Subjective adjectives: Positive terms (“amazing,” “remarkable”) receive small boosts, while negative ones (“fraud,” “toxic”) are penalized.
- Patterns: Excessive capitalization, repeated punctuation, or the presence of a DOI identifier alter the score accordingly.

This layer is linear in the length of the text and provides interpretable output: each adjustment is recorded in the explanation string. 
The approach is grounded in psycholinguistic studies demonstrating correlations between language use and perceived trustworthiness.

### ML-Based Sentiment Adjustment
To complement rules and NLP, a lightweight ML adjustment is applied:
- Preferred backend: A Hugging Face transformers sentiment pipeline, which classifies short text snippets as POSITIVE or NEGATIVE with a confidence score.
- Fallback: VADER sentiment analysis, a lexicon-based model widely used in social media studies.
- Scoring: Strong negativity leads to a modest negative adjustment (up to −3), while strong positivity leads to a smaller positive adjustment (up to +2).

The ML layer captures subtler tonal bias and hype that may elude rules, while keeping the adjustment small to preserve interpretability. 
This balance aligns with best practices in explainable AI.

## Literature Review
The design is informed by prior academic and industry work:
- **Castillo et al. (2011): Early credibility modeling for Twitter using content and user features.
- **Gupta et al. (2014): Rumor detection integrating URL features and propagation patterns.
- **Pérez-Rosas et al. (2017): Fake news detection using linguistic cues.
- **Shu et al. (2017, 2020): Surveys of fake news detection methods, noting the need for hybrid approaches.
- **Further Industry practices: NewsGuard employs human-curated domain reputations; Google integrates ClaimReview schema for fact checks; social platforms deploy ML classifiers to downrank suspected misinformation.

Current gaps include over-reliance on black-box ML models with limited interpretability, or static rule systems that are easy to circumvent. Hopefully, a hybrid design can addresses these gaps.

## Justification of Methodologies
- Rule-based heuristics offer transparency, efficiency, and immediate coverage of obvious credibility cues.
- Lexicon-based NLP provides a direct link to established linguistic markers of bias, with minimal computational cost.
- ML sentiment adjustment increases adaptability to new writing styles and provides resilience against overly simplistic rule evasion.
- Trade-offs: Rules are efficient but brittle; ML is adaptive but opaque. Combining both allows us to preserve interpretability while gradually incorporating learned signals.

Empirical validation will involve benchmarking against labeled datasets such as LIAR or FakeNewsNet, measuring classification accuracy and ranking correlation with human judgments. 
Early proof-of-concept tests confirm that the rules correctly separate reputable domains (e.g., PubMed) from low-credibility domains (e.g., freegift.click).

## Experimental Validation

To provide preliminary validation of the chosen approach, the prototype was tested against a small but illustrative set of URLs representing both highly reputable and low-credibility sources. 
The goal of these tests was not to achieve production-level accuracy, but to demonstrate that the algorithm produces outputs consistent with human expectations.

- **High-credibility domains:**  
  - Example: `https://pubmed.ncbi.nlm.nih.gov/123456/`  
    - Score: ~84  
    - Explanation: Recognized reputable domain, HTTPS, high-trust `.gov` TLD.  
  - Example: `https://www.nejm.org/doi/full/10.1056/NEJMoa2034577`  
    - Score: ~79  
    - Explanation: HTTPS, reputable scholarly publisher domain, research-oriented path.

- **Low-credibility domains:**  
  - Example: `http://freegift.click/win`  
    - Score: ~28  
    - Explanation: Low-trust `.click` TLD, HTTP protocol, suspicious lexical hints.  
  - Example: `medium.com/@someone/opinion-on-vaccines-12345`  
    - Score: ~47  
    - Explanation: Opinion-based path hint, moderate penalties applied.

The separation between credible sources (scores >75) and unreliable sources (scores <50) demonstrates that the rule-based features already provide meaningful discrimination. 
When combined with the optional NLP and ML layers, the system produces nuanced outputs: 
- For instance, an article containing a DOI but also sensational language received both positive and negative adjustments, resulting in a balanced score that better reflects its mixed signals.

These results confirm that the algorithm is functioning as intended: it rewards structural and linguistic signals of credibility while penalizing unreliable or manipulative cues. 
Future large-scale validation may employ datasets such as LIAR and FakeNewsNet to measure precision, recall, and ranking correlation against ground-truth labels, but the proof-of-concept testing provides early empirical support for the methodology.

## Roadmap and Documentation
To support reproducibility and future evolution:
- API specification:  
  `POST /score { url, page_text, use_text } to -> { score, explanation, extras }`
- Tunable parameters: Lexicon weights, ML adjustment ranges, and domain reputation lists.
- Future enhancements:  
  - Integration of automatic fact-checking APIs (e.g., ClaimBuster).  
  - Network analysis of citation relationships.  
  - Reinforcement learning from user feedback to refine weights.  
- Maintenance: Regular refresh of lexicons and reputable domain lists; updating ML backends with new misinformation detection models.

## Conclusion
This credibility scoring framework demonstrates that a hybrid approach—combining URL heuristics, interpretable linguistic rules, and modest ML adjustments—can provide accurate, transparent, and scalable assessments. 
It is grounded in both established research and practical considerations of interpretability and efficiency. The system is designed to evolve as new techniques become available while maintaining a clear, reproducible foundation.
